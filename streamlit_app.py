"""Mini interface Streamlit pour lancer le scraping, s'authentifier et exporter."""

import asyncio
import os
from pathlib import Path
import pandas as pd
import sys
import subprocess
import streamlit as st

from app.scrape import AmazonScraper
from app.utils import setup_logging, validate_asin, parse_amazon_url, detect_login_page
from app.config import settings
from app.fetch import AmazonFetcher


def run_async(coro):
    """ExÃ©cute une coroutine dans l'event loop de Streamlit."""
    return asyncio.run(coro)


async def login_headless(email: str, password: str, otp: str = "", timeout_sec: int = 120) -> bool:
    """Connexion Amazon headless rÃ©utilisable (Cloud-friendly)."""
    from app.config import settings as _settings
    fetcher = AmazonFetcher()
    old = _settings.headless
    try:
        _settings.headless = True
        await fetcher.start_browser()
        context = await fetcher.create_context()
        page = await context.new_page()

        signin_url = (
            "https://www.amazon.fr/ap/signin?_encoding=UTF8"
            "&openid.assoc_handle=frflex"
            "&openid.return_to=https%3A%2F%2Fwww.amazon.fr%2F%3Fref_%3Dnav_signin"
            "&openid.mode=checkid_setup&ignoreAuthState=1"
            "&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0"
            "&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
            "&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
        )
        await page.goto(signin_url, wait_until="domcontentloaded", timeout=_settings.timeout_ms)

        # Cookies
        for sel in (
            'input#sp-cc-accept',
            'input[data-cel-widget="sp-cc-accept"]',
            'input[name="accept"]',
        ):
            try:
                btn = await page.query_selector(sel)
                if btn:
                    await btn.click()
                    break
            except Exception:
                pass

        # Email puis mot de passe
        try:
            await page.fill('#ap_email', email)
            cont = await page.query_selector('#continue')
            if cont:
                await cont.click()
                await page.wait_for_load_state("domcontentloaded")
        except Exception:
            pass
        try:
            await page.fill('#ap_password', password)
            submit = await page.query_selector('#signInSubmit')
            if submit:
                await submit.click()
                await page.wait_for_load_state("domcontentloaded")
        except Exception:
            pass

        # OTP si demandÃ©
        try:
            otp_field = None
            for sel in ['#auth-mfa-otpcode', 'input[name="otpCode"]', 'input#otc-input']:
                otp_field = await page.query_selector(sel)
                if otp_field:
                    break
            if otp_field:
                if not otp:
                    return False
                await otp_field.fill(otp)
                for btn_sel in ['#auth-signin-button', 'input#continue', 'input[type="submit"]']:
                    btn = await page.query_selector(btn_sel)
                    if btn:
                        await btn.click()
                        await page.wait_for_load_state("domcontentloaded")
                        break
        except Exception:
            pass

        # VÃ©rifier connectÃ©
        async def _is_logged_in() -> bool:
            try:
                await page.goto("https://www.amazon.fr/gp/css/homepage.html", wait_until="domcontentloaded", timeout=_settings.timeout_ms)
                if await page.query_selector('a[href*="/gp/css/order-history"]'):
                    return True
                acc = await page.query_selector('#nav-link-accountList')
                if acc:
                    txt = (await acc.inner_text()) or ""
                    if "Identifiez-vous" not in txt:
                        return True
            except Exception:
                return False
            return False

        import time as _t
        start = _t.time()
        while _t.time() - start < timeout_sec:
            if await _is_logged_in():
                await context.storage_state(path=_settings.storage_state_path)
                await fetcher.stop_browser()
                _settings.headless = old
                return True
            await page.wait_for_timeout(1200)
        await fetcher.stop_browser()
        _settings.headless = old
        return False
    finally:
        _settings.headless = old


st.set_page_config(page_title="Amazon Reviews Scraper", layout="wide")
st.title("ðŸ›’ Amazon Reviews Scraper")
st.caption("Utilisez avec modÃ©ration et respect des CGU Amazon.")

setup_logging("INFO")

# DÃ©tection simple du runtime Cloud (pas d'affichage disponible)
IS_CLOUD = bool(os.environ.get("STREAMLIT_RUNTIME") or os.environ.get("STREAMLIT_SERVER_PORT"))

# Injecter quelques secrets Streamlit dans l'environnement si prÃ©sents (Cloud)
try:
    for key in ["AMZ_EMAIL", "AMZ_PASSWORD", "PROXY_POOL", "HEADLESS", "USE_PERSISTENT_PROFILE"]:
        if key in st.secrets:
            os.environ[key] = str(st.secrets[key])
except Exception:
    pass

# Installation Playwright browsers (Chromium) Ã  chaque dÃ©marrage (idempotent)
# Utilise le bon interprÃ©teur pour Ã©viter les problÃ¨mes de venv
try:
    # Installer navigateurs via l'interprÃ©teur courant et ne pas utiliser /usr/local/bin/python
    subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=False)
    subprocess.run([sys.executable, "-m", "playwright", "install-deps"], check=False)
except Exception:
    pass

tab1, tab2, tab3, tab4 = st.tabs(["Scraper", "Export", "Authentification", "Guide"]) 

with tab1:
    st.subheader("Scraper un ASIN")
    st.caption("Renseignez un ASIN ou une URL Amazon. Si lâ€™URL contient lâ€™ASIN, il sera dÃ©tectÃ© automatiquement.")

    # Statut de session et connexion inline
    session_state_path = getattr(settings, "storage_state_path", "./storage_state.json")
    session_ok = os.path.exists(session_state_path)
    col_s1, col_s2 = st.columns([3, 2])
    with col_s1:
        if session_ok:
            ts = Path(session_state_path).stat().st_mtime if Path(session_state_path).exists() else None
            st.success(f"Session Amazon active â€¢ {session_state_path}")
        else:
            st.warning("Aucune session Amazon active. Connectez-vous ci-dessous pour Ã©viter les redirections login/captcha.")
    with col_s2:
        test = st.button("Tester la session", help="Ouvre la page compte en tÃ¢che de fond pour vÃ©rifier l'Ã©tat.")
        if test:
            # Test simple: prÃ©sence du fichier suffit ici; test rÃ©el est effectuÃ© au premier fetch.
            st.info("Le fichier de session sera utilisÃ© au prochain lancement.")

    with st.expander("Connexion rapide (headless)", expanded=not session_ok):
        c1, c2, c3 = st.columns([2,2,1])
        with c1:
            inline_email = st.text_input("Email Amazon", value=os.environ.get("AMZ_EMAIL", ""), key="inline_email")
        with c2:
            inline_password = st.text_input("Mot de passe Amazon", value=os.environ.get("AMZ_PASSWORD", ""), type="password", key="inline_password")
        with c3:
            inline_otp = st.text_input("OTP", value="", help="2FA si demandÃ©", key="inline_otp")
        colb1, colb2 = st.columns([1,1])
        with colb1:
            if st.button("Se connecter maintenant", key="inline_login_btn"):
                with st.spinner("Connexion en coursâ€¦"):
                    ok_login = run_async(login_headless(inline_email, inline_password, inline_otp))
                if ok_login:
                    st.success(f"âœ“ Session enregistrÃ©e: {session_state_path}")
                else:
                    st.error("Connexion non dÃ©tectÃ©e. VÃ©rifiez vos identifiants/OTP, ou utilisez lâ€™onglet Authentification.")
        with colb2:
            st.file_uploader("Importer storage_state.json", type=["json"], key="inline_state_upload")
            up = st.session_state.get("inline_state_upload")
            if up is not None:
                try:
                    data = up.read()
                    with open(session_state_path, "wb") as fh:
                        fh.write(data)
                    st.success(f"âœ“ Session importÃ©e: {session_state_path}")
                except Exception:
                    st.error("Import impossible.")
    asin = st.text_input(
        "ASIN",
        placeholder="B08N5WRWNW",
        help="Identifiant produit Amazon Ã  10 caractÃ¨res alphanumÃ©riques (ex: B08N5WRWNW).",
    )
    url = st.text_input(
        "URL Amazon (produit ou avis)",
        placeholder="https://www.amazon.fr/.../dp/B0CJMJPXR1 ... ou ... /product-reviews/B0CJMJPXR1",
        help="Collez une URL de page produit ou directement de la page dâ€™avis. Lâ€™ASIN et la langue seront dÃ©duits si possible.",
    )
    language_choice = st.selectbox(
        "Langue",
        options=["Auto (dÃ©duite)", "fr_FR", "en_US", "de_DE", "es_ES", "it_IT"],
        index=0,
        help="Forcer la langue des avis. Par dÃ©faut, dÃ©duite de lâ€™URL.",
    )
    max_pages = st.number_input(
        "Nombre de pages max",
        min_value=1,
        max_value=100,
        value=2,
        help="Limite supÃ©rieure de pagination. Le scraping sâ€™arrÃªte si plus de pages ou sâ€™il nâ€™y a plus dâ€™avis.",
    )
    reset_history = st.checkbox(
        "RÃ©initialiser l'historique pour cet ASIN",
        value=False,
        help="Supprime tous les avis existants pour cet ASIN avant le run.",
    )
    verbose = st.checkbox("Mode verbeux", value=False, help="Active des logs plus dÃ©taillÃ©s pendant le scraping.")
    start = st.button("Lancer le scraping", help="DÃ©marrer le scraping selon les paramÃ¨tres ci-dessus.")

    if start:
        if url:
            parsed = parse_amazon_url(url)
            if not parsed or not parsed.get("asin"):
                st.error("URL Amazon invalide. Fournissez une URL de produit ou d'avis Amazon valide.")
                st.stop()
            asin = parsed["asin"]
        if not validate_asin(asin):
            st.error("ASIN invalide. Il doit contenir exactement 10 caractÃ¨res alphanumÃ©riques.")
        else:
            # Placeholders UX enrichis
            progress_bar = st.progress(0, text="PrÃªt Ã  dÃ©marrerâ€¦")
            stats_cols = st.columns(4)
            page_ph = stats_cols[0].empty()
            parsed_ph = stats_cols[1].empty()
            saved_ph = stats_cols[2].empty()
            duration_ph = stats_cols[3].empty()
            eta_placeholder = st.empty()
            chart_placeholder = st.empty()
            live_table_placeholder = st.empty()
            live_rows = []

            with st.status("Scraping en coursâ€¦", expanded=False) as status:
                scraper = AmazonScraper()
                run_started_at = pd.Timestamp.utcnow()
                domain = parsed.get("domain") if url else None
                # PrioritÃ© Ã  la langue choisie dans l'UI, sinon celle dÃ©duite de l'URL
                chosen_lang = None if language_choice.startswith("Auto") else language_choice
                language = chosen_lang or (parsed.get("language") if url else None)

                # Option: purge de l'historique existant pour cet ASIN
                if reset_history:
                    try:
                        deleted = scraper.delete_reviews_for_asin(asin)
                        st.info(f"Historique rÃ©initialisÃ©: {deleted} avis supprimÃ©s pour {asin}")
                    except Exception:
                        st.warning("RÃ©initialisation ignorÃ©e (erreur) â€” le scraping continue")

                # Callback de progression (appelÃ© Ã  chaque page)
                def _progress_cb(detail: dict):
                    try:
                        live_rows.append(detail)
                        df_live = pd.DataFrame(live_rows)
                        df_live = df_live[[c for c in ["page", "reviews_parsed", "saved", "duration_s", "next", "error"] if c in df_live.columns]]
                        live_table_placeholder.dataframe(df_live, use_container_width=True)
                        current_page = int(detail.get("page", 0) or 0)
                        pct = int(min(100, round((current_page / max(1, int(max_pages))) * 100)))
                        progress_bar.progress(pct, text=f"Page {current_page}/{int(max_pages)} â€¢ {pct}%")

                        # Cartes de mÃ©triques
                        page_ph.metric("Page", f"{current_page}/{int(max_pages)}")
                        parsed_ph.metric("Avis parsÃ©s (page)", int(detail.get("reviews_parsed", 0) or 0))
                        total_saved = int(df_live.get("saved", pd.Series(dtype=int)).fillna(0).sum()) if "saved" in df_live else 0
                        saved_ph.metric("Avis enregistrÃ©s (cumul)", total_saved)
                        duration_ph.metric("DurÃ©e page (s)", float(detail.get("duration_s", 0) or 0))

                        # ETA (estimation simple)
                        try:
                            if "duration_s" in df_live and not df_live["duration_s"].empty:
                                avg_dur = float(df_live["duration_s"].fillna(0).mean())
                                remaining = max(0, int(max_pages) - current_page)
                                eta_s = int(round(avg_dur * remaining))
                                if remaining > 0:
                                    eta_placeholder.caption(f"ETA ~ {eta_s}s restants (durÃ©e moyenne {avg_dur:.1f}s/page)")
                                else:
                                    eta_placeholder.caption("Presque terminÃ©â€¦")
                        except Exception:
                            pass

                        # Mini graphique (avis enregistrÃ©s par page)
                        try:
                            if "page" in df_live and "saved" in df_live:
                                df_plot = df_live[["page", "saved"]].set_index("page")
                                chart_placeholder.bar_chart(df_plot)
                        except Exception:
                            pass

                        # Mettre Ã  jour le statut en cours
                        try:
                            status.update(label=f"Traitement page {current_page}â€¦", state="running")
                        except Exception:
                            pass
                    except Exception:
                        pass

                stats = run_async(scraper.scrape_asin(
                    asin,
                    max_pages=int(max_pages),
                    domain=domain,
                    language=language,
                    progress_cb=_progress_cb,
                ))
            # Mettre Ã  jour le statut final selon le rÃ©sultat
            try:
                if stats.get("success"):
                    # Fermer proprement la barre en la remplissant Ã  100%
                    progress_bar.progress(100, text="TerminÃ© â€¢ 100%")
                else:
                    progress_bar.progress(min(100, progress_bar._value or 0), text="TerminÃ© avec erreurs")
            except Exception:
                pass
            # Affichage rÃ©capitulatif clair pour utilisateur novice
            st.markdown("### RÃ©sultat")
            status_msg_ok = (
                f"âœ… TerminÃ©: {stats.get('total_reviews',0)} avis sauvegardÃ©s sur {stats.get('total_pages',0)} pages"
                f" â€¢ {stats.get('total_encountered',0)} rencontrÃ©s"
                f" â€¢ {stats.get('total_duplicates',0)} doublons"
            )
            status_msg_warn = f"âš  TerminÃ© avec erreurs: {len(stats.get('errors', []))} erreurs"
            if stats.get("success"):
                st.success(status_msg_ok)
            else:
                st.warning(status_msg_warn)

            # DÃ©tails par page
            pages_details = stats.get("pages_details") or []
            if pages_details:
                df_pages = pd.DataFrame(pages_details)
                df_pages = df_pages[[c for c in ["page", "reviews_parsed", "saved", "duration_s", "next", "error"] if c in df_pages.columns]]
                st.markdown("#### DÃ©tail par page")
                st.dataframe(df_pages, use_container_width=True)

                # Indicateur pagination complÃ¨te
                try:
                    last_next = bool(df_pages.iloc[-1]["next"]) if not df_pages.empty and "next" in df_pages.columns else None
                    total_pages = int(stats.get("total_pages") or len(df_pages))
                    asked_pages = int(max_pages)
                    is_complete = (total_pages == asked_pages) or (last_next is False)
                    st.caption(f"Pagination: {total_pages}/{asked_pages} pages â€¢ " + ("âœ… complÃ¨te" if is_complete else "âš  incomplÃ¨te"))
                except Exception:
                    pass

                # Export du dÃ©tail de pagination
                csv_pages = df_pages.to_csv(index=False).encode("utf-8")
                st.download_button("Exporter le dÃ©tail de pagination (CSV)", data=csv_pages, file_name=f"pages_details_{asin}.csv", mime="text/csv")

            # (section fusionnÃ©e ci-dessous)

            # RÃ©sultats & aperÃ§u (fusion: derniers 10 + aperÃ§u triÃ©)
            try:
                # PrioritÃ© aux avis insÃ©rÃ©s pendant ce run
                try:
                    recent_inserted = scraper.get_reviews_for_asin_since(asin, created_after=run_started_at.to_pydatetime())
                except Exception:
                    recent_inserted = []
                if recent_inserted:
                    all_reviews = pd.DataFrame(recent_inserted)
                else:
                    all_reviews = pd.DataFrame(scraper.get_reviews_for_asin(asin))
                if not all_reviews.empty:
                    # DÃ©duplication de secours cÃ´tÃ© UI pour garantir zÃ©ro doublon visible
                    dedupe_cols = [c for c in ["asin", "review_title", "review_body", "review_date"] if c in all_reviews.columns]
                    if dedupe_cols:
                        all_reviews = all_reviews.drop_duplicates(subset=dedupe_cols, keep="first")
                    def _sentiment_from_rating(r: float) -> str:
                        try:
                            val = float(r)
                        except Exception:
                            return "Neutre"
                        if val >= 4:
                            return "Positif"
                        if val <= 2:
                            return "NÃ©gatif"
                        return "Neutre"
                    st.markdown("#### RÃ©sultats et aperÃ§u")
                    tab_last, tab_preview = st.tabs(["Chronologique", "AperÃ§u triÃ© par sentiment"])

                    # Vue 1: Derniers 10 avis (par date de crÃ©ation si dispo, sinon review_date)
                    with tab_last:
                        sort_cols = [c for c in ["created_at", "review_date"] if c in all_reviews.columns]
                        df_last = all_reviews.copy()
                        if sort_cols:
                            df_last = df_last.sort_values(sort_cols, ascending=[False] * len(sort_cols))
                        cols_last = [c for c in ["review_id", "review_date", "rating", "review_title", "review_body", "reviewer_name", "variant"] if c in df_last.columns]
                        st.dataframe(df_last[cols_last], use_container_width=True)
                        # Exports de la vue chronologique complÃ¨te
                        c1, c2 = st.columns(2)
                        with c1:
                            st.download_button(
                                "CSV (chronologique)",
                                data=df_last.to_csv(index=False).encode("utf-8"),
                                file_name=f"reviews_chrono_{asin}.csv",
                                mime="text/csv",
                                key=f"dl_chrono_csv_{asin}",
                            )
                        with c2:
                            try:
                                import io
                                out = io.BytesIO()
                                with pd.ExcelWriter(out, engine="openpyxl") as writer:
                                    df_last.to_excel(writer, index=False, sheet_name="chronologique")
                                st.download_button(
                                    "Excel (chronologique)",
                                    data=out.getvalue(),
                                    file_name=f"reviews_chrono_{asin}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"dl_chrono_xlsx_{asin}",
                                )
                            except Exception:
                                pass

                    # Vue 2: AperÃ§u triÃ© par sentiment
                    with tab_preview:
                        all_reviews["sentiment"] = all_reviews.get("rating", 0).apply(_sentiment_from_rating)
                        order = ["Positif", "Neutre", "NÃ©gatif"]
                        all_reviews["sentiment"] = pd.Categorical(all_reviews["sentiment"], categories=order, ordered=True)
                        df_preview = all_reviews.sort_values(["sentiment", "review_date"], ascending=[True, False])
                        st.dataframe(df_preview, use_container_width=True)

                        col1, col2 = st.columns(2)
                        with col1:
                            csv_bytes = df_preview.to_csv(index=False).encode("utf-8")
                            st.download_button(
                                "CSV (aperÃ§u triÃ©)",
                                data=csv_bytes,
                                file_name=f"reviews_{asin}.csv",
                                mime="text/csv",
                                key=f"dl_csv_sorted_{asin}",
                            )
                        with col2:
                            try:
                                import io
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                                    df_preview.to_excel(writer, index=False, sheet_name="reviews")
                                st.download_button(
                                    "Excel (aperÃ§u triÃ©)",
                                    data=output.getvalue(),
                                    file_name=f"reviews_{asin}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"dl_xlsx_sorted_{asin}",
                                )
                            except Exception:
                                pass
            except Exception:
                pass

            # Afficher erreurs si prÃ©sentes
            if stats.get("errors"):
                with st.expander("Voir les erreurs"):
                    for err in stats["errors"]:
                        st.write(f"- {err}")

with tab2:
    st.subheader("Exporter les avis")
    st.caption("TÃ©lÃ©chargez les avis dÃ©jÃ  stockÃ©s en base. Laissez lâ€™ASIN vide pour exporter tout le jeu de donnÃ©es.")
    # Conserver l'Ã©tat entre les reruns pour Ã©viter la disparition des boutons aprÃ¨s clic
    if "export_df" not in st.session_state:
        st.session_state["export_df"] = None
    asin_filter = st.text_input(
        "Filtrer par ASIN (optionnel)",
        help="Exporter uniquement les avis correspondant Ã  cet ASIN. Laissez vide pour tout exporter.",
    )
    limit = st.number_input(
        "Limiter le nombre d'avis (optionnel)",
        min_value=0,
        max_value=10000,
        value=0,
        help="0 pour aucune limite. Utile pour Ã©chantillonner les donnÃ©es.",
    )
    do_export = st.button("PrÃ©parer l'export", help="PrÃ©parer les fichiers tÃ©lÃ©chargeables ci-dessous.")

    if do_export:
        scraper = AmazonScraper()
        lim = int(limit) if limit > 0 else None
        data = scraper.get_reviews_for_asin(asin_filter, lim) if asin_filter else scraper.get_all_reviews(lim)
        if not data:
            st.session_state["export_df"] = None
            st.info("Aucun avis en base.")
        else:
            st.session_state["export_df"] = pd.DataFrame(data)

    # Proposer les deux formats d'export tant que des donnÃ©es sont prÃªtes
    if st.session_state.get("export_df") is not None:
        df = st.session_state["export_df"]
        col_a, col_b = st.columns(2)
        with col_a:
            st.download_button(
                "TÃ©lÃ©charger CSV",
                data=df.to_csv(index=False).encode("utf-8"),
                file_name="reviews.csv",
                mime="text/csv",
                key="dl_csv_global",
            )
        with col_b:
            try:
                import io
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df.to_excel(writer, index=False, sheet_name="reviews")
                st.download_button(
                    "TÃ©lÃ©charger Excel",
                    data=output.getvalue(),
                    file_name="reviews.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="dl_xlsx_global",
                )
            except Exception:
                st.warning("Excel indisponible: vÃ©rifiez l'installation d'openpyxl.")

with tab3:
    st.subheader("Authentification Amazon")
    st.caption("Ouvrez une fenÃªtre pour vous connecter, la session sera enregistrÃ©e.")
    with st.expander("Comment Ã§a marche ?"):
        st.markdown(
            "- Une fenÃªtre Amazon sâ€™ouvre avec Playwright.\n"
            "- Connectez-vous normalement (email, mot de passe, 2FA si nÃ©cessaire).\n"
            "- Ã€ la dÃ©tection de session valide, lâ€™Ã©tat est sauvegardÃ© pour les prochains scrapings."
        )

    session_state_path = getattr(settings, "storage_state_path", "./storage_state.json")
    if os.path.exists(session_state_path):
        st.success(f"Session trouvÃ©e: {session_state_path}")
    else:
        st.info("Aucune session enregistrÃ©e.")

    # Mode Cloud: proposer une connexion headless via formulaire (pas de fenÃªtre graphique)
    st.markdown("---")
    st.caption("Connexion headless (compatible Cloud)")
    colx, coly = st.columns(2)
    with colx:
        email_input = st.text_input("Email Amazon", value="", placeholder="prenom.nom@mail.com")
    with coly:
        password_input = st.text_input("Mot de passe Amazon", value="", type="password")
    otp_input = st.text_input("Code 2FA (si demandÃ©)", value="", help="Laissez vide si Amazon ne le demande pas")
    do_headless_login = st.button("Se connecter (headless)", help="Tentative de connexion en arriÃ¨re-plan, sans fenÃªtre graphique.")

    if do_headless_login:
        if not email_input or not password_input:
            st.error("Renseignez email et mot de passe.")
        else:
            with st.spinner("Connexion en coursâ€¦"):
                async def run_headless_login(timeout_sec: int = 120) -> bool:
                    # Forcer headless en Cloud
                    old = settings.headless
                    try:
                        settings.headless = True
                        fetcher = AmazonFetcher()
                        await fetcher.start_browser()
                        context = await fetcher.create_context()
                        page = await context.new_page()
                        signin_url = (
                            "https://www.amazon.fr/ap/signin?_encoding=UTF8"
                            "&openid.assoc_handle=frflex"
                            "&openid.return_to=https%3A%2F%2Fwww.amazon.fr%2F%3Fref_%3Dnav_signin"
                            "&openid.mode=checkid_setup&ignoreAuthState=1"
                            "&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0"
                            "&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
                            "&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
                        )
                        await page.goto(signin_url, wait_until="domcontentloaded", timeout=settings.timeout_ms)
                        try:
                            # Cookies
                            for sel in [
                                'input#sp-cc-accept',
                                'input[data-cel-widget="sp-cc-accept"]',
                                'input[name="accept"]',
                            ]:
                                btn = await page.query_selector(sel)
                                if btn:
                                    await btn.click()
                                    break
                        except Exception:
                            pass
                        # Email -> Continuer
                        try:
                            await page.fill('#ap_email', email_input)
                            cont = await page.query_selector('#continue')
                            if cont:
                                await cont.click()
                                await page.wait_for_load_state("domcontentloaded")
                        except Exception:
                            pass
                        # Password -> Sign in
                        try:
                            await page.fill('#ap_password', password_input)
                            submit = await page.query_selector('#signInSubmit')
                            if submit:
                                await submit.click()
                                await page.wait_for_load_state("domcontentloaded")
                        except Exception:
                            pass
                        # OTP (2FA) si demandÃ©
                        try:
                            otp_selectors = [
                                '#auth-mfa-otpcode',
                                'input[name="otpCode"]',
                                'input[name="code"]',
                                'input#otc-input',
                            ]
                            otp_field = None
                            for sel in otp_selectors:
                                otp_field = await page.query_selector(sel)
                                if otp_field:
                                    break
                            if otp_field:
                                if not otp_input:
                                    # Pas de code fourni par l'utilisateur
                                    return False
                                await otp_field.fill(otp_input)
                                # Boutons possibles de validation
                                for btn_sel in ['#auth-signin-button', 'input#continue', 'input[type="submit"]']:
                                    btn = await page.query_selector(btn_sel)
                                    if btn:
                                        await btn.click()
                                        await page.wait_for_load_state("domcontentloaded")
                                        break
                        except Exception:
                            pass
                        # VÃ©rifier l'Ã©tat connectÃ© via plusieurs heuristiques
                        async def _is_logged_in() -> bool:
                            try:
                                # 1) Page compte: prÃ©sence d'Ã©lÃ©ments du hub compte
                                await page.goto("https://www.amazon.fr/gp/css/homepage.html", wait_until="domcontentloaded", timeout=settings.timeout_ms)
                                if await page.query_selector('a[href*="/gp/css/order-history"]'):
                                    return True
                                # 2) Barre de nav: texte diffÃ©rent d'"Identifiez-vous"
                                acc = await page.query_selector('#nav-link-accountList')
                                if acc:
                                    txt = (await acc.inner_text()) or ""
                                    if "Identifiez-vous" not in txt:
                                        return True
                                # 3) Lien de dÃ©connexion prÃ©sent
                                if await page.query_selector('#nav-item-signout, a[href*="/gp/flex/sign-out"]'):
                                    return True
                            except Exception:
                                return False
                            return False

                        # Attente borne avec boucles courtes
                        import time as _t
                        start = _t.time()
                        logged = False
                        while _t.time() - start < timeout_sec:
                            if await _is_logged_in():
                                logged = True
                                break
                            await page.wait_for_timeout(1200)
                        if logged:
                            await context.storage_state(path=session_state_path)
                        await fetcher.stop_browser()
                        settings.headless = old
                        return logged
                    finally:
                        settings.headless = old

                ok2 = asyncio.run(run_headless_login())
                if ok2:
                    st.success(f"âœ“ Session enregistrÃ©e: {session_state_path}")
                else:
                    st.error("Connexion non dÃ©tectÃ©e (captcha/2FA possible). RÃ©essayez ou uploadez un storage_state.")

    st.markdown("---")
    st.caption("Alternative: charger un fichier de session (storage_state.json)")
    uploaded = st.file_uploader("Fichier storage_state.json", type=["json"], accept_multiple_files=False)
    if uploaded is not None:
        try:
            data = uploaded.read()
            with open(session_state_path, "wb") as fh:
                fh.write(data)
            st.success(f"âœ“ Session importÃ©e: {session_state_path}")
        except Exception:
            st.error("Import de session impossible.")

with tab4:
    st.subheader("Guide dâ€™utilisation")
    st.markdown("""
### 1) Scraper un produit
- Renseignez un **ASIN** ou collez une **URL Amazon** (produit ou avis). Si lâ€™URL contient lâ€™ASIN, il sera dÃ©tectÃ©.
- Choisissez la **langue** (ou laissez en Auto). RÃ©glez le **nombre de pages max**.
- Cliquez sur **Lancer le scraping**. Suivez la **progression** et le **dÃ©tail par page**.

### 2) Exporter les avis
- Allez dans lâ€™onglet **Export**. Filtrez par **ASIN** si besoin, sinon laissez vide.
- Choisissez le **format** (CSV ou Parquet) puis cliquez sur **Exporter**.

### 3) Authentification Amazon
- Ouvrez une fenÃªtre de connexion depuis lâ€™onglet **Authentification**.
- Connectez-vous; la **session** est enregistrÃ©e pour les scrapings suivants.

### Conseils et bonnes pratiques
- Respectez les **CGU Amazon** et limitez la frÃ©quence (pauses min/max dans la barre latÃ©rale).
- Pour une meilleure stabilitÃ©, commencez avec **peu de pages** puis augmentez.
- Surveillez la section **erreurs** en fin de scraping. Relancez si besoin.

### DÃ©pannage
- Si aucune donnÃ©e nâ€™apparaÃ®t: vÃ©rifiez lâ€™ASIN/URL et la **langue**.
- Si Amazon demande un captcha/2FA: passez par lâ€™onglet **Authentification** puis rÃ©essayez.
- Erreurs rÃ©seau sporadiques: **relancez** le scraping, rÃ©duisez **pages max**, augmentez les **pauses**.
    """)

st.sidebar.header("Configuration rapide")
st.sidebar.caption("ParamÃ¨tres appliquÃ©s au processus courant. Utiles pour ajuster le rythme et la stabilitÃ©.")
headless = st.sidebar.checkbox("Headless (recommandÃ©)", value=True, help="ExÃ©cute le navigateur sans interface graphique pour plus de performances.")
pages_env = st.sidebar.number_input("Pages max par dÃ©faut", min_value=1, max_value=100, value=5, help="Valeur utilisÃ©e si vous ne prÃ©cisez pas de limite dans lâ€™onglet Scraper.")
sleep_min = st.sidebar.number_input("Pause min (s)", min_value=0.0, value=2.0, help="DÃ©lai minimum alÃ©atoire entre les pages.")
sleep_max = st.sidebar.number_input("Pause max (s)", min_value=0.0, value=4.0, help="DÃ©lai maximum alÃ©atoire entre les pages.")

if st.sidebar.button("Appliquer", help="Enregistrer ces paramÃ¨tres dans les variables dâ€™environnement du processus courant."):
    # Applique Ã  l'environnement courant du process (simple)
    os.environ["HEADLESS"] = "true" if headless else "false"
    os.environ["MAX_PAGES_PER_ASIN"] = str(int(pages_env))
    os.environ["SLEEP_MIN"] = str(float(sleep_min))
    os.environ["SLEEP_MAX"] = str(float(sleep_max))
    st.sidebar.success("Configuration appliquÃ©e (process courant)")

st.sidebar.markdown("---")
st.sidebar.write("Pour lancer:")
st.sidebar.code("streamlit run streamlit_app.py")


