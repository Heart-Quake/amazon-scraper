"""Mini interface Streamlit pour lancer le scraping, s'authentifier et exporter."""

import asyncio
import os
from pathlib import Path
import pandas as pd
import sys
import subprocess
import streamlit as st

from app.scrape import AmazonScraper
from app.utils import setup_logging, validate_asin, parse_amazon_url, detect_login_page
from app.config import settings
from app.fetch import AmazonFetcher


def run_async(coro):
    """Ex√©cute une coroutine dans l'event loop de Streamlit."""
    return asyncio.run(coro)


async def login_headless(email: str, password: str, otp: str = "", timeout_sec: int = 120) -> bool:
    """Connexion Amazon headless r√©utilisable (Cloud-friendly)."""
    from app.config import settings as _settings
    fetcher = AmazonFetcher()
    old = _settings.headless
    try:
        _settings.headless = True
        await fetcher.start_browser()
        context = await fetcher.create_context()
        page = await context.new_page()

        signin_url = (
            "https://www.amazon.fr/ap/signin?_encoding=UTF8"
            "&openid.assoc_handle=frflex"
            "&openid.return_to=https%3A%2F%2Fwww.amazon.fr%2F%3Fref_%3Dnav_signin"
            "&openid.mode=checkid_setup&ignoreAuthState=1"
            "&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0"
            "&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
            "&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
        )
        await page.goto(signin_url, wait_until="domcontentloaded", timeout=_settings.timeout_ms)

        # Cookies
        for sel in (
            'input#sp-cc-accept',
            'input[data-cel-widget="sp-cc-accept"]',
            'input[name="accept"]',
        ):
            try:
                btn = await page.query_selector(sel)
                if btn:
                    await btn.click()
                    break
            except Exception:
                pass

        # Email puis mot de passe
        try:
            await page.fill('#ap_email', email)
            cont = await page.query_selector('#continue')
            if cont:
                await cont.click()
                await page.wait_for_load_state("domcontentloaded")
        except Exception:
            pass
        try:
            await page.fill('#ap_password', password)
            submit = await page.query_selector('#signInSubmit')
            if submit:
                await submit.click()
                await page.wait_for_load_state("domcontentloaded")
        except Exception:
            pass

        # OTP si demand√©
        try:
            otp_field = None
            for sel in ['#auth-mfa-otpcode', 'input[name="otpCode"]', 'input#otc-input']:
                otp_field = await page.query_selector(sel)
                if otp_field:
                    break
            if otp_field:
                if not otp:
                    return False
                await otp_field.fill(otp)
                for btn_sel in ['#auth-signin-button', 'input#continue', 'input[type="submit"]']:
                    btn = await page.query_selector(btn_sel)
                    if btn:
                        await btn.click()
                        await page.wait_for_load_state("domcontentloaded")
                        break
        except Exception:
            pass

        # V√©rifier connect√©
        async def _is_logged_in() -> bool:
            try:
                await page.goto("https://www.amazon.fr/gp/css/homepage.html", wait_until="domcontentloaded", timeout=_settings.timeout_ms)
                if await page.query_selector('a[href*="/gp/css/order-history"]'):
                    return True
                acc = await page.query_selector('#nav-link-accountList')
                if acc:
                    txt = (await acc.inner_text()) or ""
                    if "Identifiez-vous" not in txt:
                        return True
            except Exception:
                return False
            return False

        import time as _t
        start = _t.time()
        while _t.time() - start < timeout_sec:
            if await _is_logged_in():
                await context.storage_state(path=_settings.storage_state_path)
                await fetcher.stop_browser()
                _settings.headless = old
                return True
            await page.wait_for_timeout(1200)
        await fetcher.stop_browser()
        _settings.headless = old
        return False
    finally:
        _settings.headless = old


st.set_page_config(page_title="Amazon Reviews Scraper", layout="wide")
st.title("üõí Amazon Reviews Scraper")
st.caption("Utilisez avec mod√©ration et respect des CGU Amazon.")

setup_logging("INFO")

# D√©tection simple du runtime Cloud (pas d'affichage disponible)
IS_CLOUD = bool(os.environ.get("STREAMLIT_RUNTIME") or os.environ.get("STREAMLIT_SERVER_PORT"))

# Injecter quelques secrets Streamlit dans l'environnement si pr√©sents (Cloud)
try:
    for key in ["AMZ_EMAIL", "AMZ_PASSWORD", "PROXY_POOL", "HEADLESS", "USE_PERSISTENT_PROFILE"]:
        if key in st.secrets:
            os.environ[key] = str(st.secrets[key])
except Exception:
    pass

# Installation Playwright browsers (Chromium) √† chaque d√©marrage (idempotent)
# Utilise le bon interpr√©teur pour √©viter les probl√®mes de venv
try:
    # Installer navigateurs via l'interpr√©teur courant et ne pas utiliser /usr/local/bin/python
    subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=False)
    subprocess.run([sys.executable, "-m", "playwright", "install-deps"], check=False)
except Exception:
    pass

tab1, tab2, tab3, tab4 = st.tabs(["Scraper", "Export", "Authentification", "Guide"]) 

with tab1:
    st.subheader("Scraper un ASIN")
    st.caption("Renseignez un ASIN ou une URL Amazon. Si l‚ÄôURL contient l‚ÄôASIN, il sera d√©tect√© automatiquement.")

    # Statut de session et connexion inline
    session_state_path = getattr(settings, "storage_state_path", "./storage_state.json")
    session_ok = os.path.exists(session_state_path)
    col_s1, col_s2 = st.columns([3, 2])
    with col_s1:
        if session_ok:
            ts = Path(session_state_path).stat().st_mtime if Path(session_state_path).exists() else None
            st.success(f"Session Amazon active ‚Ä¢ {session_state_path}")
        else:
            st.warning("Aucune session Amazon active. Connectez-vous ci-dessous pour √©viter les redirections login/captcha.")
    with col_s2:
        test = st.button("Tester la session", help="Ouvre la page compte en t√¢che de fond pour v√©rifier l'√©tat.")
        if test:
            # Test simple: pr√©sence du fichier suffit ici; test r√©el est effectu√© au premier fetch.
            st.info("Le fichier de session sera utilis√© au prochain lancement.")

    with st.expander("Connexion rapide (headless)", expanded=not session_ok):
        c1, c2, c3 = st.columns([2,2,1])
        with c1:
            inline_email = st.text_input("Email Amazon", value=os.environ.get("AMZ_EMAIL", ""), key="inline_email")
        with c2:
            inline_password = st.text_input("Mot de passe Amazon", value=os.environ.get("AMZ_PASSWORD", ""), type="password", key="inline_password")
        with c3:
            inline_otp = st.text_input("OTP", value="", help="2FA si demand√©", key="inline_otp")
        colb1, colb2 = st.columns([1,1])
        with colb1:
            if st.button("Se connecter maintenant", key="inline_login_btn"):
                with st.spinner("Connexion en cours‚Ä¶"):
                    ok_login = run_async(login_headless(inline_email, inline_password, inline_otp))
                if ok_login:
                    st.success(f"‚úì Session enregistr√©e: {session_state_path}")
                else:
                    st.error("Connexion non d√©tect√©e. V√©rifiez vos identifiants/OTP, ou utilisez l‚Äôonglet Authentification.")
        with colb2:
            st.file_uploader("Importer storage_state.json", type=["json"], key="inline_state_upload")
            up = st.session_state.get("inline_state_upload")
            if up is not None:
                try:
                    data = up.read()
                    with open(session_state_path, "wb") as fh:
                        fh.write(data)
                    st.success(f"‚úì Session import√©e: {session_state_path}")
                except Exception:
                    st.error("Import impossible.")
    asin = st.text_input(
        "ASIN",
        placeholder="B08N5WRWNW",
        help="Identifiant produit Amazon √† 10 caract√®res alphanum√©riques (ex: B08N5WRWNW).",
    )
    url = st.text_input(
        "URL Amazon (produit ou avis)",
        placeholder="https://www.amazon.fr/.../dp/B0CJMJPXR1 ... ou ... /product-reviews/B0CJMJPXR1",
        help="Collez une URL de page produit ou directement de la page d‚Äôavis. L‚ÄôASIN et la langue seront d√©duits si possible.",
    )
    language_choice = st.selectbox(
        "Langue",
        options=["Auto (d√©duite)", "fr_FR", "en_US", "de_DE", "es_ES", "it_IT"],
        index=0,
        help="Forcer la langue des avis. Par d√©faut, d√©duite de l‚ÄôURL.",
    )
    max_pages = st.number_input(
        "Nombre de pages max",
        min_value=1,
        max_value=100,
        value=2,
        help="Limite sup√©rieure de pagination. Le scraping s‚Äôarr√™te si plus de pages ou s‚Äôil n‚Äôy a plus d‚Äôavis.",
    )
    reset_history = st.checkbox(
        "R√©initialiser l'historique pour cet ASIN",
        value=False,
        help="Supprime tous les avis existants pour cet ASIN avant le run.",
    )
    verbose = st.checkbox("Mode verbeux", value=False, help="Active des logs plus d√©taill√©s pendant le scraping.")
    start = st.button("Lancer le scraping", help="D√©marrer le scraping selon les param√®tres ci-dessus.")

    if start:
        if url:
            parsed = parse_amazon_url(url)
            if not parsed or not parsed.get("asin"):
                st.error("URL Amazon invalide. Fournissez une URL de produit ou d'avis Amazon valide.")
                st.stop()
            asin = parsed["asin"]
        if not validate_asin(asin):
            st.error("ASIN invalide. Il doit contenir exactement 10 caract√®res alphanum√©riques.")
        else:
            # Placeholders UX enrichis
            progress_bar = st.progress(0, text="Pr√™t √† d√©marrer‚Ä¶")
            stats_cols = st.columns(4)
            page_ph = stats_cols[0].empty()
            parsed_ph = stats_cols[1].empty()
            saved_ph = stats_cols[2].empty()
            duration_ph = stats_cols[3].empty()
            eta_placeholder = st.empty()
            chart_placeholder = st.empty()
            live_table_placeholder = st.empty()
            live_rows = []

            with st.status("Scraping en cours‚Ä¶", expanded=False) as status:
                scraper = AmazonScraper()
                run_started_at = pd.Timestamp.utcnow()
                domain = parsed.get("domain") if url else None
                # Priorit√© √† la langue choisie dans l'UI, sinon celle d√©duite de l'URL
                chosen_lang = None if language_choice.startswith("Auto") else language_choice
                language = chosen_lang or (parsed.get("language") if url else None)

                # Option: purge de l'historique existant pour cet ASIN
                if reset_history:
                    try:
                        deleted = scraper.delete_reviews_for_asin(asin)
                        st.info(f"Historique r√©initialis√©: {deleted} avis supprim√©s pour {asin}")
                    except Exception:
                        st.warning("R√©initialisation ignor√©e (erreur) ‚Äî le scraping continue")

                # Callback de progression (appel√© √† chaque page)
                def _progress_cb(detail: dict):
                    try:
                        live_rows.append(detail)
                        df_live = pd.DataFrame(live_rows)
                        df_live = df_live[[c for c in ["page", "reviews_parsed", "saved", "duration_s", "next", "error"] if c in df_live.columns]]
                        live_table_placeholder.dataframe(df_live, use_container_width=True)
                        current_page = int(detail.get("page", 0) or 0)
                        pct = int(min(100, round((current_page / max(1, int(max_pages))) * 100)))
                        progress_bar.progress(pct, text=f"Page {current_page}/{int(max_pages)} ‚Ä¢ {pct}%")

                        # Cartes de m√©triques
                        page_ph.metric("Page", f"{current_page}/{int(max_pages)}")
                        parsed_ph.metric("Avis pars√©s (page)", int(detail.get("reviews_parsed", 0) or 0))
                        total_saved = int(df_live.get("saved", pd.Series(dtype=int)).fillna(0).sum()) if "saved" in df_live else 0
                        saved_ph.metric("Avis enregistr√©s (cumul)", total_saved)
                        duration_ph.metric("Dur√©e page (s)", float(detail.get("duration_s", 0) or 0))

                        # ETA (estimation simple)
                        try:
                            if "duration_s" in df_live and not df_live["duration_s"].empty:
                                avg_dur = float(df_live["duration_s"].fillna(0).mean())
                                remaining = max(0, int(max_pages) - current_page)
                                eta_s = int(round(avg_dur * remaining))
                                if remaining > 0:
                                    eta_placeholder.caption(f"ETA ~ {eta_s}s restants (dur√©e moyenne {avg_dur:.1f}s/page)")
                                else:
                                    eta_placeholder.caption("Presque termin√©‚Ä¶")
                        except Exception:
                            pass

                        # Mini graphique (avis enregistr√©s par page)
                        try:
                            if "page" in df_live and "saved" in df_live:
                                df_plot = df_live[["page", "saved"]].set_index("page")
                                chart_placeholder.bar_chart(df_plot)
                        except Exception:
                            pass

                        # Mettre √† jour le statut en cours
                        try:
                            status.update(label=f"Traitement page {current_page}‚Ä¶", state="running")
                        except Exception:
                            pass
                    except Exception:
                        pass

                stats = run_async(scraper.scrape_asin(
                    asin,
                    max_pages=int(max_pages),
                    domain=domain,
                    language=language,
                    progress_cb=_progress_cb,
                ))
            # Mettre √† jour le statut final selon le r√©sultat
            try:
                if stats.get("success"):
                    # Fermer proprement la barre en la remplissant √† 100%
                    progress_bar.progress(100, text="Termin√© ‚Ä¢ 100%")
                else:
                    progress_bar.progress(min(100, progress_bar._value or 0), text="Termin√© avec erreurs")
            except Exception:
                pass
            # Affichage r√©capitulatif clair pour utilisateur novice
            st.markdown("### R√©sultat")
            status_msg_ok = (
                f"‚úÖ Termin√©: {stats.get('total_reviews',0)} avis sauvegard√©s sur {stats.get('total_pages',0)} pages"
                f" ‚Ä¢ {stats.get('total_encountered',0)} rencontr√©s"
                f" ‚Ä¢ {stats.get('total_duplicates',0)} doublons"
            )
            status_msg_warn = f"‚ö† Termin√© avec erreurs: {len(stats.get('errors', []))} erreurs"
            if stats.get("success"):
                st.success(status_msg_ok)
            else:
                st.warning(status_msg_warn)

            # D√©tails par page
            pages_details = stats.get("pages_details") or []
            if pages_details:
                df_pages = pd.DataFrame(pages_details)
                df_pages = df_pages[[c for c in ["page", "reviews_parsed", "saved", "duration_s", "next", "error"] if c in df_pages.columns]]
                st.markdown("#### D√©tail par page")
                st.dataframe(df_pages, use_container_width=True)

                # Indicateur pagination compl√®te
                try:
                    last_next = bool(df_pages.iloc[-1]["next"]) if not df_pages.empty and "next" in df_pages.columns else None
                    total_pages = int(stats.get("total_pages") or len(df_pages))
                    asked_pages = int(max_pages)
                    is_complete = (total_pages == asked_pages) or (last_next is False)
                    st.caption(f"Pagination: {total_pages}/{asked_pages} pages ‚Ä¢ " + ("‚úÖ compl√®te" if is_complete else "‚ö† incompl√®te"))
                except Exception:
                    pass

                # Export du d√©tail de pagination
                csv_pages = df_pages.to_csv(index=False).encode("utf-8")
                st.download_button("Exporter le d√©tail de pagination (CSV)", data=csv_pages, file_name=f"pages_details_{asin}.csv", mime="text/csv")

            # (section fusionn√©e ci-dessous)

            # R√©sultats & aper√ßu (fusion: derniers 10 + aper√ßu tri√©)
            try:
                # Priorit√© aux avis ins√©r√©s pendant ce run
                try:
                    recent_inserted = scraper.get_reviews_for_asin_since(asin, created_after=run_started_at.to_pydatetime())
                except Exception:
                    recent_inserted = []
                if recent_inserted:
                    all_reviews = pd.DataFrame(recent_inserted)
                else:
                    all_reviews = pd.DataFrame(scraper.get_reviews_for_asin(asin))
                if not all_reviews.empty:
                    # D√©duplication de secours c√¥t√© UI pour garantir z√©ro doublon visible
                    dedupe_cols = [c for c in ["asin", "review_title", "review_body", "review_date"] if c in all_reviews.columns]
                    if dedupe_cols:
                        all_reviews = all_reviews.drop_duplicates(subset=dedupe_cols, keep="first")
                    def _sentiment_from_rating(r: float) -> str:
                        try:
                            val = float(r)
                        except Exception:
                            return "Neutre"
                        if val >= 4:
                            return "Positif"
                        if val <= 2:
                            return "N√©gatif"
                        return "Neutre"
                    st.markdown("#### R√©sultats et aper√ßu")
                    tab_last, tab_preview = st.tabs(["Chronologique", "Aper√ßu tri√© par sentiment"])

                    # Vue 1: Derniers 10 avis (par date de cr√©ation si dispo, sinon review_date)
                    with tab_last:
                        sort_cols = [c for c in ["created_at", "review_date"] if c in all_reviews.columns]
                        df_last = all_reviews.copy()
                        if sort_cols:
                            df_last = df_last.sort_values(sort_cols, ascending=[False] * len(sort_cols))
                        cols_last = [c for c in ["review_id", "review_date", "rating", "review_title", "review_body", "reviewer_name", "variant"] if c in df_last.columns]
                        st.dataframe(df_last[cols_last], use_container_width=True)
                        # Exports de la vue chronologique compl√®te
                        c1, c2 = st.columns(2)
                        with c1:
                            st.download_button(
                                "CSV (chronologique)",
                                data=df_last.to_csv(index=False).encode("utf-8"),
                                file_name=f"reviews_chrono_{asin}.csv",
                                mime="text/csv",
                                key=f"dl_chrono_csv_{asin}",
                            )
                        with c2:
                            try:
                                import io
                                out = io.BytesIO()
                                with pd.ExcelWriter(out, engine="openpyxl") as writer:
                                    df_last.to_excel(writer, index=False, sheet_name="chronologique")
                                st.download_button(
                                    "Excel (chronologique)",
                                    data=out.getvalue(),
                                    file_name=f"reviews_chrono_{asin}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"dl_chrono_xlsx_{asin}",
                                )
                            except Exception:
                                pass

                    # Vue 2: Aper√ßu tri√© par sentiment
                    with tab_preview:
                        all_reviews["sentiment"] = all_reviews.get("rating", 0).apply(_sentiment_from_rating)
                        order = ["Positif", "Neutre", "N√©gatif"]
                        all_reviews["sentiment"] = pd.Categorical(all_reviews["sentiment"], categories=order, ordered=True)
                        df_preview = all_reviews.sort_values(["sentiment", "review_date"], ascending=[True, False])
                        st.dataframe(df_preview, use_container_width=True)

                        col1, col2 = st.columns(2)
                        with col1:
                            csv_bytes = df_preview.to_csv(index=False).encode("utf-8")
                            st.download_button(
                                "CSV (aper√ßu tri√©)",
                                data=csv_bytes,
                                file_name=f"reviews_{asin}.csv",
                                mime="text/csv",
                                key=f"dl_csv_sorted_{asin}",
                            )
                        with col2:
                            try:
                                import io
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                                    df_preview.to_excel(writer, index=False, sheet_name="reviews")
                                st.download_button(
                                    "Excel (aper√ßu tri√©)",
                                    data=output.getvalue(),
                                    file_name=f"reviews_{asin}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"dl_xlsx_sorted_{asin}",
                                )
                            except Exception:
                                pass
            except Exception:
                pass

            # Afficher erreurs si pr√©sentes
            if stats.get("errors"):
                with st.expander("Voir les erreurs"):
                    for err in stats["errors"]:
                        st.write(f"- {err}")

with tab2:
    st.subheader("Exporter les avis")
    st.caption("T√©l√©chargez les avis d√©j√† stock√©s en base. Laissez l‚ÄôASIN vide pour exporter tout le jeu de donn√©es.")
    # Conserver l'√©tat entre les reruns pour √©viter la disparition des boutons apr√®s clic
    if "export_df" not in st.session_state:
        st.session_state["export_df"] = None
    asin_filter = st.text_input(
        "Filtrer par ASIN (optionnel)",
        help="Exporter uniquement les avis correspondant √† cet ASIN. Laissez vide pour tout exporter.",
    )
    limit = st.number_input(
        "Limiter le nombre d'avis (optionnel)",
        min_value=0,
        max_value=10000,
        value=0,
        help="0 pour aucune limite. Utile pour √©chantillonner les donn√©es.",
    )
    do_export = st.button("Pr√©parer l'export", help="Pr√©parer les fichiers t√©l√©chargeables ci-dessous.")

    if do_export:
        scraper = AmazonScraper()
        lim = int(limit) if limit > 0 else None
        data = scraper.get_reviews_for_asin(asin_filter, lim) if asin_filter else scraper.get_all_reviews(lim)
        if not data:
            st.session_state["export_df"] = None
            st.info("Aucun avis en base.")
        else:
            st.session_state["export_df"] = pd.DataFrame(data)

    # Proposer les deux formats d'export tant que des donn√©es sont pr√™tes
    if st.session_state.get("export_df") is not None:
        df = st.session_state["export_df"]
        col_a, col_b = st.columns(2)
        with col_a:
            st.download_button(
                "T√©l√©charger CSV",
                data=df.to_csv(index=False).encode("utf-8"),
                file_name="reviews.csv",
                mime="text/csv",
                key="dl_csv_global",
            )
        with col_b:
            try:
                import io
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine="openpyxl") as writer:
                    df.to_excel(writer, index=False, sheet_name="reviews")
                st.download_button(
                    "T√©l√©charger Excel",
                    data=output.getvalue(),
                    file_name="reviews.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key="dl_xlsx_global",
                )
            except Exception:
                st.warning("Excel indisponible: v√©rifiez l'installation d'openpyxl.")

with tab3:
    st.subheader("Authentification Amazon")
    st.caption("Ouvrez une fen√™tre pour vous connecter, la session sera enregistr√©e.")
    with st.expander("Comment √ßa marche ?"):
        st.markdown(
            "- Une fen√™tre Amazon s‚Äôouvre avec Playwright.\n"
            "- Connectez-vous normalement (email, mot de passe, 2FA si n√©cessaire).\n"
            "- √Ä la d√©tection de session valide, l‚Äô√©tat est sauvegard√© pour les prochains scrapings."
        )

    session_state_path = getattr(settings, "storage_state_path", "./storage_state.json")
    if os.path.exists(session_state_path):
        st.success(f"Session trouv√©e: {session_state_path}")
    else:
        st.info("Aucune session enregistr√©e.")

    # Mode Cloud: proposer une connexion headless via formulaire (pas de fen√™tre graphique)
    st.markdown("---")
    st.caption("Connexion headless (compatible Cloud)")
    colx, coly = st.columns(2)
    with colx:
        email_input = st.text_input("Email Amazon", value="", placeholder="prenom.nom@mail.com")
    with coly:
        password_input = st.text_input("Mot de passe Amazon", value="", type="password")
    otp_input = st.text_input("Code 2FA (si demand√©)", value="", help="Laissez vide si Amazon ne le demande pas")
    do_headless_login = st.button("Se connecter (headless)", help="Tentative de connexion en arri√®re-plan, sans fen√™tre graphique.")

    if do_headless_login:
        if not email_input or not password_input:
            st.error("Renseignez email et mot de passe.")
        else:
            with st.spinner("Connexion en cours‚Ä¶"):
                async def run_headless_login(timeout_sec: int = 120) -> bool:
                    # Forcer headless en Cloud
                    old = settings.headless
                    try:
                        settings.headless = True
                        fetcher = AmazonFetcher()
                        await fetcher.start_browser()
                        context = await fetcher.create_context()
                        page = await context.new_page()
                        signin_url = (
                            "https://www.amazon.fr/ap/signin?_encoding=UTF8"
                            "&openid.assoc_handle=frflex"
                            "&openid.return_to=https%3A%2F%2Fwww.amazon.fr%2F%3Fref_%3Dnav_signin"
                            "&openid.mode=checkid_setup&ignoreAuthState=1"
                            "&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0"
                            "&openid.claimed_id=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
                            "&openid.identity=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0%2Fidentifier_select"
                        )
                        await page.goto(signin_url, wait_until="domcontentloaded", timeout=settings.timeout_ms)
                        try:
                            # Cookies
                            for sel in [
                                'input#sp-cc-accept',
                                'input[data-cel-widget="sp-cc-accept"]',
                                'input[name="accept"]',
                            ]:
                                btn = await page.query_selector(sel)
                                if btn:
                                    await btn.click()
                                    break
                        except Exception:
                            pass
                        # Email -> Continuer
                        try:
                            await page.fill('#ap_email', email_input)
                            cont = await page.query_selector('#continue')
                            if cont:
                                await cont.click()
                                await page.wait_for_load_state("domcontentloaded")
                        except Exception:
                            pass
                        # Password -> Sign in
                        try:
                            await page.fill('#ap_password', password_input)
                            submit = await page.query_selector('#signInSubmit')
                            if submit:
                                await submit.click()
                                await page.wait_for_load_state("domcontentloaded")
                        except Exception:
                            pass
                        # OTP (2FA) si demand√©
                        try:
                            otp_selectors = [
                                '#auth-mfa-otpcode',
                                'input[name="otpCode"]',
                                'input[name="code"]',
                                'input#otc-input',
                            ]
                            otp_field = None
                            for sel in otp_selectors:
                                otp_field = await page.query_selector(sel)
                                if otp_field:
                                    break
                            if otp_field:
                                if not otp_input:
                                    # Pas de code fourni par l'utilisateur
                                    return False
                                await otp_field.fill(otp_input)
                                # Boutons possibles de validation
                                for btn_sel in ['#auth-signin-button', 'input#continue', 'input[type="submit"]']:
                                    btn = await page.query_selector(btn_sel)
                                    if btn:
                                        await btn.click()
                                        await page.wait_for_load_state("domcontentloaded")
                                        break
                        except Exception:
                            pass
                        # V√©rifier l'√©tat connect√© via plusieurs heuristiques
                        async def _is_logged_in() -> bool:
                            try:
                                # 1) Page compte: pr√©sence d'√©l√©ments du hub compte
                                await page.goto("https://www.amazon.fr/gp/css/homepage.html", wait_until="domcontentloaded", timeout=settings.timeout_ms)
                                if await page.query_selector('a[href*="/gp/css/order-history"]'):
                                    return True
                                # 2) Barre de nav: texte diff√©rent d'"Identifiez-vous"
                                acc = await page.query_selector('#nav-link-accountList')
                                if acc:
                                    txt = (await acc.inner_text()) or ""
                                    if "Identifiez-vous" not in txt:
                                        return True
                                # 3) Lien de d√©connexion pr√©sent
                                if await page.query_selector('#nav-item-signout, a[href*="/gp/flex/sign-out"]'):
                                    return True
                            except Exception:
                                return False
                            return False

                        # Attente borne avec boucles courtes
                        import time as _t
                        start = _t.time()
                        logged = False
                        while _t.time() - start < timeout_sec:
                            if await _is_logged_in():
                                logged = True
                                break
                            await page.wait_for_timeout(1200)
                        if logged:
                            await context.storage_state(path=session_state_path)
                        await fetcher.stop_browser()
                        settings.headless = old
                        return logged
                    finally:
                        settings.headless = old

                ok2 = asyncio.run(run_headless_login())
                if ok2:
                    st.success(f"‚úì Session enregistr√©e: {session_state_path}")
                else:
                    st.error("Connexion non d√©tect√©e (captcha/2FA possible). R√©essayez ou uploadez un storage_state.")

    st.markdown("---")
    st.caption("Alternative: charger un fichier de session (storage_state.json)")
    uploaded = st.file_uploader("Fichier storage_state.json", type=["json"], accept_multiple_files=False)
    if uploaded is not None:
        try:
            data = uploaded.read()
            with open(session_state_path, "wb") as fh:
                fh.write(data)
            st.success(f"‚úì Session import√©e: {session_state_path}")
        except Exception:
            st.error("Import de session impossible.")

with tab4:
    st.subheader("Guide d‚Äôutilisation")
    st.markdown("""
### 1) Scraper un produit
- Renseignez un **ASIN** ou collez une **URL Amazon** (produit ou avis). Si l‚ÄôURL contient l‚ÄôASIN, il sera d√©tect√©.
- Choisissez la **langue** (ou laissez en Auto). R√©glez le **nombre de pages max**.
- Cliquez sur **Lancer le scraping**. Suivez la **progression** et le **d√©tail par page**.

### 2) Exporter les avis
- Allez dans l‚Äôonglet **Export**. Filtrez par **ASIN** si besoin, sinon laissez vide.
- Choisissez le **format** (CSV ou Parquet) puis cliquez sur **Exporter**.

### 3) Authentification Amazon
- Ouvrez une fen√™tre de connexion depuis l‚Äôonglet **Authentification**.
- Connectez-vous; la **session** est enregistr√©e pour les scrapings suivants.

### Conseils et bonnes pratiques
- Respectez les **CGU Amazon** et limitez la fr√©quence (pauses min/max dans la barre lat√©rale).
- Pour une meilleure stabilit√©, commencez avec **peu de pages** puis augmentez.
- Surveillez la section **erreurs** en fin de scraping. Relancez si besoin.

### D√©pannage
- Si aucune donn√©e n‚Äôappara√Æt: v√©rifiez l‚ÄôASIN/URL et la **langue**.
- Si Amazon demande un captcha/2FA: passez par l‚Äôonglet **Authentification** puis r√©essayez.
- Erreurs r√©seau sporadiques: **relancez** le scraping, r√©duisez **pages max**, augmentez les **pauses**.
    """)

st.sidebar.header("Configuration rapide")
st.sidebar.caption("Param√®tres appliqu√©s au processus courant. Utiles pour ajuster le rythme et la stabilit√©.")
headless = st.sidebar.checkbox("Headless (recommand√©)", value=True, help="Ex√©cute le navigateur sans interface graphique pour plus de performances.")
pages_env = st.sidebar.number_input("Pages max par d√©faut", min_value=1, max_value=100, value=5, help="Valeur utilis√©e si vous ne pr√©cisez pas de limite dans l‚Äôonglet Scraper.")
sleep_min = st.sidebar.number_input("Pause min (s)", min_value=0.0, value=2.0, help="D√©lai minimum al√©atoire entre les pages.")
sleep_max = st.sidebar.number_input("Pause max (s)", min_value=0.0, value=4.0, help="D√©lai maximum al√©atoire entre les pages.")

if st.sidebar.button("Appliquer", help="Enregistrer ces param√®tres dans les variables d‚Äôenvironnement du processus courant."):
    # Applique √† l'environnement courant du process (simple)
    os.environ["HEADLESS"] = "true" if headless else "false"
    os.environ["MAX_PAGES_PER_ASIN"] = str(int(pages_env))
    os.environ["SLEEP_MIN"] = str(float(sleep_min))
    os.environ["SLEEP_MAX"] = str(float(sleep_max))
    st.sidebar.success("Configuration appliqu√©e (process courant)")

st.sidebar.markdown("---")
st.sidebar.write("Pour lancer:")
st.sidebar.code("streamlit run streamlit_app.py")


